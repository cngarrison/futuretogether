---
id: 9
title: "What does a good future actually look like?"
date: "2026-02-19"
excerpt: "Most of what Future Together talks about focuses on risk. This is the other post — the one that asks what we're actually working toward, and why it's worth the effort."
author: "Charles N. Garrison"
tags: [
  "AI",
  "AI Impact",
  "Future Of Work",
  "Positive Vision",
  "Medical Breakthroughs",
  "Human Flourishing",
  "AI Safety",
]
---

# What does a good future actually look like?

If you've spent any time with Future Together — the meetups, this blog, the founding essay — you've encountered a lot of discomfort.

The gap between what's actually happening and what most people understand. The acceleration that surprises even the people building these systems. The questions that don't have clean answers: Will AI systems remain aligned with human values as they become more capable? What happens to the careers and livelihoods that have anchored people's identities for decades? What do communities look like on the other side of an economic transition we can't fully map in advance?

Those are honest questions, and Future Together isn't going to stop asking them. Naming the uncomfortable reality clearly is one of the things we're here for.

But this is the post I've been meaning to write for a while. Not the risks. The upside. What a good future looks like — concretely, specifically — and why it's actually worth working toward rather than simply hoping for.

Because hope isn't naive if it's grounded in what's actually possible. And what's actually possible, if we navigate this well, is remarkable.

---

## Near-term: Freeing people from drudgery

Let me start with something that doesn't get named clearly enough.

A significant portion of what most people do at work — across almost every industry — is genuinely tedious. Not complex problem-solving. Not human connection. Not creativity. The routine. The administrative overhead. The processing, the formatting, the filing, the chasing, the correspondence that follows a predictable script.

AI is already capable of handling most of that. Not perfectly, and not without oversight — but well enough that the ratio of time spent on meaningful work versus drudgery is starting to shift. For people who've integrated these tools seriously, what used to consume entire days now takes hours. What used to take hours takes minutes.

The optimistic version of this story — and I think it's the right version, if we get the transition right — is that this frees people to do the parts of their work that only humans can do. The judgment calls. The relationships. The nuance that comes from lived experience. The creative leaps that require you to have actually lived a life.

Nobody goes into nursing to do paperwork. Nobody becomes a teacher because they love marking. Nobody started a small business because they wanted to spend their weekends on compliance documentation. The drudgery is what people endure to get to the work they actually care about. The possibility — not guaranteed, but real — is that the ratio shifts. That more of the day is spent on the part that matters.

---

## Near-term: Democratising access that was previously reserved for the privileged

Here's a fact about the world as it currently exists: high-quality advice is rationed by price.

A good lawyer costs money most people don't have. A good therapist often has a waiting list months long and charges rates that make weekly sessions a significant luxury. Good medical advice — not the ten-minute GP appointment, but the extended diagnostic conversation with a specialist who has time to think through your case carefully — is available if you can pay for it privately, and much harder to access if you can't.

This isn't a criticism of lawyers, therapists, or doctors. It's a structural reality. There are not enough of them, the training takes too long, and the economics of their practice create access gaps that fall hardest on the people with the least margin.

AI is already beginning to close those gaps in meaningful ways.

A therapist I know described her experience of clients who've started working through problems with AI between sessions — or instead of sessions when cost became a barrier. Her reaction was honest and complex: she's worried about her profession, and she also believes, genuinely, that people who couldn't otherwise access therapeutic conversations are now having them. The benefit is real, even when the disruption to her field is real too. She holds both truths without pretending the discomfort doesn't exist.

The same shift is happening in legal advice, in medical information, in financial planning. Not perfectly — AI systems make mistakes, carry biases, and can give confident-sounding answers that are wrong. None of that should be minimised. But the alternative isn't a world where everyone had a personal lawyer and therapist and financial advisor on retainer. It's a world where most people navigated these areas with minimal support, or with whatever Google turned up.

A good future is one where expertise isn't rationed by your postcode or your bank account. We're not there yet. We're moving toward it.

---

## Medium-term: Compressing decades of medical research

I want to spend more time on medicine, because the scale of what might be possible is hard to hold in the mind all at once.

Dario Amodei — one of the founders of Anthropic, the AI safety company — wrote an essay called *Machines of Loving Grace* that I'd encourage anyone to read. In it, he argues that AI has the potential to compress fifty to a hundred years of biological and medical research into somewhere between five and ten years. Not as a prediction — as a considered assessment of what's within reach if current trajectories hold.

Consider what that would mean in concrete terms.

Drug discovery currently works like this: researchers identify a promising compound, test it through years of trials, fail more often than they succeed, and bring a new drug to market after a process that typically spans ten to fifteen years and costs billions of dollars. Most diseases that affect smaller populations don't get that investment at all, because the economics don't justify it.

AI doesn't change biology. But it changes the speed at which hypotheses can be tested and eliminated. It changes the ability to model how compounds interact with biological systems before a single clinical trial. It changes the economics of researching conditions that affect populations too small to attract traditional pharmaceutical investment.

The same compression applies to understanding the fundamental mechanisms of aging, the drivers of mental illness, the relationship between the microbiome and chronic disease — areas where progress has been slow not because researchers aren't brilliant, but because the search space is enormous and human attention is finite.

We have been watching people we love suffer from conditions we don't understand and can't effectively treat for the whole of human history. The possibility — real, not guaranteed, but real — is that the next generation faces a meaningfully different situation. That diseases which are currently progressive and fatal become manageable. That conditions which cause decades of suffering become treatable in years rather than in lifetimes.

If that sounds like science fiction, it's worth reading Amodei's essay. He's not a techno-utopian fantasist. He runs one of the organisations most seriously engaged with AI safety, because he understands both the promise and the danger. [Read it here.](https://darioamodei.com/machines-of-loving-grace)

---

## Maslow's pyramid: What we're really talking about

There's a framework that helps me hold all of this together, and I suspect you already know it.

Maslow's hierarchy of needs. The pyramid with physiological needs at the base — food, water, shelter, sleep — moving up through safety, belonging, esteem, and at the top, self-actualisation: the ability to pursue meaning, creativity, growth, purpose.

The pyramid matters because it describes something true about the human condition: you can't reliably pursue the upper levels while the lower levels are insecure. Someone who doesn't know where their next meal is coming from can't think clearly about their sense of purpose. Someone experiencing a health crisis that could be addressed but isn't, because they can't afford specialist care, is not fully free to live at the higher levels of the pyramid.

Most of human history has been a story of most people spending most of their lives at the bottom of the pyramid, with insufficient security to consistently reach for anything higher.

A good future — the one we're working toward — is one where the base of the pyramid is genuinely more secure for more people. Where the drudgery that consumes people's working hours shrinks, freeing mental and emotional space for things that matter more. Where the expertise rationed by wealth becomes more widely accessible. Where the diseases that cut lives short or make them smaller could be treated — or even cured.

This is not a promise of utopia. It's a description of what becomes possible when the fundamental constraints on human flourishing loosen. People still have to choose what to do with that freedom. Communities still have to decide what they value. Meaning still has to be found, not handed down.

But the question of what more people could reach for, if the base of the pyramid were more secure — that's one of the most interesting questions I can imagine. And it's a question we might actually get to explore.

---

## The condition that changes everything

I have to be honest with you about what all of this depends on.

None of what I've described above is automatic. The future I've sketched is real in the sense that it's technically within reach. It is not inevitable.

The productivity gains are real, but they don't automatically flow to workers. They can be captured by capital instead — and history suggests that's often what happens, unless there are deliberate choices made about how the benefits are distributed.

The democratisation of access is real, but AI systems built without care can encode the same biases as the systems they replace, and reach more people with those biases more efficiently.

The medical breakthroughs are real as a trajectory, but they depend on institutions, investment, and research culture aligning toward them — and on the technology itself remaining trustworthy enough that people are willing to rely on it.

And underlying all of this: the good future depends on getting [AI alignment](/blog/what-is-ai-alignment-and-why-is-it-so-hard) right.

An AI system that is capable enough to compress decades of medical research is also capable enough to cause serious harm if it pursues objectives that diverge from human values — even slightly, even without malicious intent. The same capabilities that make it useful make the stakes of misalignment high.

This is not a reason to stop. It is the central reason that Future Together exists.

The future I've described isn't going to happen by accident. It happens because people understand what's at stake — both the promise and the danger — and push accordingly. Because the conversation about how these systems should be built, deployed, and governed is informed by people who've thought carefully about it. Because the institutions and governments and companies making decisions about AI feel the weight of a public that is paying attention.

That's not naive. That's how change actually works.

---

## This is what we're working toward

I want to end with something clear.

Future Together is not a doom community. We don't gather to feel afraid together. We gather because the gap between what's actually happening and what most people understand is enormous, and that gap is dangerous — not because understanding will guarantee a good outcome, but because *not* understanding makes a good outcome much less likely.

The future I've described is worth working toward. Genuinely. Not as a consolation prize — as a real possibility for what human life could look like if we navigate this well.

More people living at the higher levels of Maslow's pyramid. More of the working day spent on work that actually matters. The beginning of medical breakthroughs that previous generations could only dream of. Expertise reaching people who couldn't afford it. Complexity becoming accessible.

That's what's on the table. And the way it gets realised — or doesn't — depends in part on how many people are aware of what's happening and engaged with what it means.

If you want to understand the risks more clearly, [the alignment post](/blog/what-is-ai-alignment-and-why-is-it-so-hard) is a good place to start. If you want to think about what preparation actually looks like, [the community post](/blog/why-community-is-the-most-important-preparation) will give you something to hold onto.

And if you want to have this conversation with people who are thinking carefully about it — come to the meetup. That's what it's for.

---

*The future is arriving. Let's face it together.*

*[Join the next meetup →](/events/discuss-our-future)*
